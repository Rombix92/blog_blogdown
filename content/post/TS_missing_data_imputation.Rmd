---
description: 
title: TS - missing data imputation
categories: ['Time Series']
tags: ['missing data','time series','imputation']
date: '2022-10-26'
toc: true
---

```{r markdown_parameters, include=FALSE}

#markdown ----
knitr::opts_chunk$set(#fig.width=12, 
                      fig.height=4,
                       out.width = '100%'
                      ) 
knitr::opts_chunk$set(include =TRUE, #prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks.

                      warning = FALSE,
                      message =FALSE,
                      collapse=TRUE,
                      error=TRUE
                      )
options(scipen=999)
```



```{r, include =FALSE}

library(reticulate)
myenvs=conda_list()
envname=myenvs$name[5]
use_condaenv(envname, required = TRUE)
```

```{r, include =FALSE}
data_file_path = '/Users/lrabalski1/Desktop/prv/data/'
```

```{r}
require(zoo)
require(data.table)
library(dplyr)
library(lubridate)

unemp <- fread(paste0(data_file_path,"bezrobocie_USA.csv")) %>% data.table::melt( id.vars='Year',
                                                           variable.name = "months",
                                                           value.name='UNRATE') %>% left_join(
  data.frame(month_nr=c(1:12),
             months= c("Jan","Feb","Mar",
                       "Apr","May","Jun",
                       "Jul","Aug","Sep",
                       "Oct","Nov","Dec"))
) %>% mutate(DATE=as_date('0000-01-01',format = '%Y-%m-%d')+years(as.numeric(Year)) + months(month_nr-1)) 

head(unemp)


unemp = unemp[, DATE := as.Date(DATE)][!is.na(UNRATE),.(DATE, UNRATE)]
setkey(unemp, DATE)

## Creating dataset with random missing values
rand.unemp.idx <- sample(1:nrow(unemp), .1*nrow(unemp))
rand.unemp <- unemp[-rand.unemp.idx]

## Creating dataset with systematical missing values, appearing in month with highest unemployment rate
high.unemp.idx <- which(unemp$UNRATE > 8)
high.unemp.idx <- sample(high.unemp.idx, .5 * length(high.unemp.idx))
bias.unemp <- unemp[-high.unemp.idx]


## to identyfy missing data I wil use rolling joins tool from data.table package    
all.dates <- seq(from = unemp$DATE[1], to = tail(unemp$DATE, 1), by = "months")
rand.unemp = rand.unemp[J(all.dates), roll=FALSE]
bias.unemp = bias.unemp[J(all.dates), roll=FALSE]

## forward filling
rand.unemp[, impute.ff := na.locf(UNRATE, na.rm = FALSE)]
bias.unemp[, impute.ff := na.locf(UNRATE, na.rm = FALSE)]

## Mean moving average with use of lookahead phenomen
rand.unemp[, impute.rm.lookahead := rollapply(data=c(UNRATE,NA, NA), width=3,
          FUN= function(x) {
                         if (!is.na(x[1])) x[1] else mean(x, na.rm = TRUE)
                         })]         
bias.unemp[, impute.rm.lookahead := rollapply(c(UNRATE, NA,NA), 3,
            FUN= function(x) {
                         if (!is.na(x[1])) x[1] else mean(x, na.rm = TRUE)
                         })]         



## Mean moving average withou use of lookahead phenomen
rand.unemp[, impute.rm.nolookahead := rollapply(c(NA, NA, UNRATE), 3,
             function(x) {
                         if (!is.na(x[3])) x[3] else mean(x, na.rm = TRUE)
                         })]         
bias.unemp[, impute.rm.nolookahead := rollapply(c(NA, NA, UNRATE), 3,
             function(x) {
                         if (!is.na(x[3])) x[3] else mean(x, na.rm = TRUE)
                         })]    





## linear interpolation fullfilling NA with linear interpolation between two data points
rand.unemp[, impute.li := na.approx(UNRATE, maxgap=Inf)]
bias.unemp[, impute.li := na.approx(UNRATE)]

zz <- c(NA, 9, 3, NA, 3, 2,NA,5,6,10,NA,NA,NA,0)
na.approx(zz, na.rm = FALSE, maxgap=2)
na.approx(zz, na.rm = FALSE, maxgap=Inf)
na.approx(zz,xout=11, na.rm = FALSE, maxgap=Inf)





## Using root mean square error to compare methods
sort(rand.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
             .SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li")])

sort(bias.unemp[ , lapply(.SD, function(x) mean((x - unemp$UNRATE)^2, na.rm = TRUE)),
             .SDcols = c("impute.ff", "impute.rm.nolookahead", "impute.rm.lookahead", "impute.li")])


smoothed = unemp[, HoltWinters(UNRATE, alpha = 0.1, beta = FALSE, gamma = FALSE)]

```

```{python}
import pandas as pd

unemp = r.unemp
unemp.index = unemp.DATE

## We can use the pandas.DataFrame.ewm() function to calculate the exponentially weighted moving average for a certain number of previous periods.
```

alpha -  smoothing factor

$0 < \alpha \leq 1$


When adjust=False, the exponentially weighted function is calculated recursively:

$$\begin{split}\begin{split}
y_0 &= x_0\\
y_t &= (1 - \alpha) y_{t-1} + \alpha x_t,
\end{split}\end{split}$$

The higher is alpha the lower impact of the most fresh data

```{python}
unemp['Smooth.1'] = unemp.UNRATE.ewm(alpha=0.1,adjust=False,).mean()
unemp['Smooth.2'] = unemp.UNRATE.ewm(alpha=0.2,adjust=False).mean()

unemp['Smooth.3'] = unemp.UNRATE.ewm(alpha=0.3,adjust=False,).mean()

import matplotlib.pyplot as plt
import datetime

plt.clf()
plt.plot(unemp['UNRATE'], label='raw')
plt.plot(unemp['Smooth.1'], label='Smooth.1')
plt.plot(unemp['Smooth.2'], label='Smooth.2')
plt.plot(unemp['Smooth.3'], label='Smooth.3')
plt.xlim([datetime.date(2015, 1, 1), datetime.date(2022, 1, 1)])
plt.legend(loc=2)
plt.show()

```